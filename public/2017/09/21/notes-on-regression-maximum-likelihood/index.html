<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Notes on Regression - Maximum Likelihood</title>
  <meta property="og:title" content="Notes on Regression - Maximum Likelihood" />
  <meta name="twitter:title" content="Notes on Regression - Maximum Likelihood" />
  <meta name="description" content="Part 4 in the series of notes on regression analysis derives the OLS formula through the maximum likelihood approach. Maximum likelihood involves finding the value of the parameters that maximise the probably of the observed data under an assumption of the distribution of the distribution of the random variables.
Bernoulli exampleTake for example a dataset consisting of the results of a series of coin flips. The coin may be biased and we want to find an estimator for the probability of the coin landing heads.">
  <meta property="og:description" content="Part 4 in the series of notes on regression analysis derives the OLS formula through the maximum likelihood approach. Maximum likelihood involves finding the value of the parameters that maximise the probably of the observed data under an assumption of the distribution of the distribution of the random variables.
Bernoulli exampleTake for example a dataset consisting of the results of a series of coin flips. The coin may be biased and we want to find an estimator for the probability of the coin landing heads.">
  <meta name="twitter:description" content="Part 4 in the series of notes on regression analysis derives the OLS formula through the maximum likelihood approach. Maximum likelihood involves finding the value of the parameters that maximise the …">
  <meta name="author" content="Timothy Lin"/>
  <meta name="twitter:card" content="summary" />
  <meta property="og:url" content="https://www.timlrx.com/2017/09/21/notes-on-regression-maximum-likelihood/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="Quasilinear Musings" />

  <meta name="generator" content="Hugo 0.20.7" />
  <link rel="canonical" href="https://www.timlrx.com/2017/09/21/notes-on-regression-maximum-likelihood/" />
  <link rel="alternate" href="https://www.timlrx.com/index.xml" type="application/rss+xml" title="Quasilinear Musings">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  <link rel="stylesheet" href="https://www.timlrx.com/css/main.css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://www.timlrx.com/css/pygment_highlights.css" />
  <link rel="stylesheet" href="https://www.timlrx.com/css/highlight.min.css" />



<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-100201704-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>

</head>

  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://www.timlrx.com/">Quasilinear Musings</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="../../../../post/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="../../../../about/">About</a>
            </li>
          
        
          
            <li>
              <a title="SG-Dashboard" href="../../../../dashboard/sg-dashboard/">SG-Dashboard</a>
            </li>
          
        
          
            <li>
              <a title="Categories" href="../../../../categories">Categories</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="../../../../tags">Tags</a>
            </li>
          
        

        

        
      </ul>
    </div>

    <div class="avatar-container">
      <div class="avatar-img-border">
        
      </div>
    </div>

  </div>
</nav>




    
  
  
  




  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              <h1>Notes on Regression - Maximum Likelihood</h1>
                
                
                  <span class="post-meta">
  Posted on September 21, 2017
  
</span>


                
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <p>Part 4 in the series of notes on regression analysis derives the OLS formula through the maximum likelihood approach. Maximum likelihood involves finding the value of the parameters that maximise the probably of the observed data under an assumption of the distribution of the distribution of the random variables.</p>
<div id="bernoulli-example" class="section level3">
<h3>Bernoulli example</h3>
<p>Take for example a dataset consisting of the results of a series of coin flips. The coin may be biased and we want to find an estimator for the probability of the coin landing heads. A fair assumption is that observations are drawn from <span class="math inline">\(n\)</span> independent coin flips drawn from the same <span class="math inline">\(Bernoulli(p)\)</span> distribution. This means that the probability mass function of a single observation <span class="math inline">\(x_{i}\)</span> is given by: <span class="math display">\[
f(x_{i};p) = p^{x_{i}}(1-p)^{1-x_{i}}
\]</span> Note that <span class="math inline">\(x_{i}\)</span> is a single observation and takes the value of 0 or 1. The likelihood function can be written as: <span class="math display">\[
\begin{aligned}
L(p) &amp;= P(X_{1}=x_{1}, X_{2}=x_{2},...,X_{n}=x_{n}; p) \\
&amp;= \prod_{i=1}^{n} f(x_{i};p)~~(\text{by independence})\\
&amp;= p^{\sum x_{i}} (1-p)^{n - \sum x_{i}}
\end{aligned}
\]</span></p>
<p>Now we want to find the value <span class="math inline">\(p\)</span> that maximises the likelihood, <span class="math inline">\(L(p)\)</span>. One can alternatively maximise the log likelihood which makes the derivation easier.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> The maximum likelihood estimate can then be calculated by finding the value <span class="math inline">\(p\)</span> that maximises the log likelihood:</p>
<p><span class="math display">\[
\begin{aligned}
ln L(p) &amp;= (\sum x_{i}) ln~p + (n - \sum x_{i}) ln (1-p) \\
\frac{\partial ln L(p)}{\partial p} &amp;= \frac{\sum x_{i}}{p} - \frac{n - \sum x_{i}}{1 -p} \\
0 &amp;= (1-p)\sum x_{i} - p(n - \sum x_{i}) \\
\hat{p} &amp;= \frac{\sum x_{i}}{n}
\end{aligned}
\]</span> Not surprisingly, the probability that the biased coin will land heads is simply the average number of heads across all observations.</p>
</div>
<div id="linear-regression" class="section level3">
<h3>Linear regression</h3>
<p>Similarly, one can derive the formula for the OLS estimator through the maximum likelihood approach. Recall that the linearity implies the following specification for the regression model: <span class="math inline">\(y_{i} = \mathbf{x}_{i}&#39;\beta + u_{i}\)</span>. In the maximum likelihood approach, we need to assume that the error terms conditional on <span class="math inline">\(x_{i}\)</span> are normally distributed with unknown variance i.e. $ u_{i} | _{i} N(0,^2)$. The PDF of a single observation is given by: <span class="math display">\[
f(y_{i},\mathbf{x}_{i};\beta, \sigma^2) = 
\frac{1}{\sqrt{2\pi\sigma^2}} exp(\frac{-(y_{i} -\mathbf{x}&#39;_{i}\beta)^2}{2\sigma^2})
\]</span> The likelihood or the joint PDF is: <span class="math display">\[
L(\beta, \sigma^2) = \prod_{i=1}^{n}
\frac{1}{\sqrt{2\pi\sigma^2}} exp(\frac{-(y_{i} -\mathbf{x}&#39;_{i}\beta)^2}{2\sigma^2})
\]</span> The log likelihood can be written as: <span class="math display">\[
\begin{aligned}
ln~L(\beta, \sigma^2) &amp;= ln \prod_{i=1}^{n} f(y_{i},\mathbf{x}_{i};\beta, \sigma^2) \\
&amp;= \sum_{i=1}^{n} ln~f(y_{i},\mathbf{x}_{i};\beta, \sigma^2) \\
&amp;= \sum_{i=1}^{n} ln~\Big( 
\frac{1}{\sqrt{2\pi\sigma^2}} exp(\frac{-(y_{i} -\mathbf{x}&#39;_{i}\beta)^2}{2\sigma^2}) \Big) \\
&amp;= -\frac{n}{2} ln~2\pi -\frac{n}{2} ln~\sigma^2 -\frac{1}{2\sigma^2}\sum_{i=1}^{n}(y_{i} -\mathbf{x}&#39;_{i}\beta)^2
\end{aligned}
\]</span> Take the derivative with respect to <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma\)</span> to derive the maximum likelihood estimator:</p>
<p><span class="math display">\[
\begin{aligned}
\beta_{ML} &amp;= (\sum_{i=1}^{n}\mathbf{x}_{i}\mathbf{x}_{i}&#39;)^{-1}(\sum_{i=1}^{n}\mathbf{x}_{i}y_{i}) \\
\sigma^{2}_{ML} &amp;= \frac{\sum_{i=1}^{n}(y_{i} -\mathbf{x}&#39;_{i}\beta)^2}{n}
\end{aligned}
\]</span></p>
</div>
<div id="additional-comments" class="section level3">
<h3>Additional Comments</h3>
<p>While the maximum likelihood estimator can only be derived only under very strong assumptions of the functional form which the error term takes, it is a very popular method in statistics and has many other applications. For example, binary choice models such as probit and logit assume that the dependent variable takes the value of 0 or 1 and could be modelled using the following functional form:</p>
<p><span class="math display">\[
P(y_{i}=1 | \mathbf{x}_{i}) = f(\mathbf{x}_{i}&#39;\beta)
\]</span> where f is the CDF for the normal distribution in the case of the probit model or the logistic CDF for the logistic regression.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<p>In most cases, such as the logit model discussed above, there is no explicit solution for the maximisation problem and the solution has to be derived using numerical optimisation.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Since the <span class="math inline">\(ln\)</span> function is monotonic, the parameter value that maximises the log likelihood will also maximise the likelihood.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>This corresponds to a latent variable model where the error terms are iid drawn from a normal or logistic distribution.<a href="#fnref2">↩</a></p></li>
</ol>
</div>

      </article>

      <ul class="pager blog-pager">
        
          <li class="previous">
            <a href="https://www.timlrx.com/2017/09/13/using-leaflet-in-r-tutorial/" data-toggle="tooltip" data-placement="top" title="Using Leaflet in R - Tutorial">&larr; Previous Post</a>
          </li>
        
        
      </ul>

      

    </div>
  </div>
</div>

    <footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:timothy.lin@alumni.ubc.ca" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://github.com/timlrx" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/timothy-lin-0600ba141" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            <a href="https://www.timlrx.com/index.xml" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          Timothy Lin
          &nbsp;&bull;&nbsp;
          2017

          
            &nbsp;&bull;&nbsp;
            <a href="https://www.timlrx.com/">Quasilinear Musings</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="http://gohugo.io">Hugo v0.20.7</a> powered &nbsp;&bull;&nbsp; Theme by <a href="http://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a> adapted to <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a>
          
        </p>
      </div>
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha384-dq1/gEHSxPZQ7DdrM82ID4YVol9BYyU7GbWlIwnwyPzotpoc57wDw/guX8EaYGPx" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="https://www.timlrx.com/js/main.js"></script>
<script src="https://www.timlrx.com/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> renderMathInElement(document.body); </script>






  </body>
</html>

